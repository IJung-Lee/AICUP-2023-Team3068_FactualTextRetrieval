{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dc033a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertConfig, BertForSequenceClassification, BertPreTrainedModel, BertModel\n",
    "import json\n",
    "from torch.utils.data import TensorDataset, random_split, Subset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66a9f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa51102d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test = json.load(open('D:\\\\download\\\\比賽\\\\CHEF-sbert\\\\Pipeline\\\\Data\\\\CHEF_train_hfl_pretraineds_0511sentBase_document_article_epoch50_0519_BM25F_V3.json', 'r', encoding='utf-8'))\n",
    "test = json.load(open('D:\\\\download\\\\比賽\\\\CHEF-sbert\\\\Pipeline\\\\Data\\\\CHEF_test_hfl_pretraineds_0511sentBase_document_article_epoch50_0519_BM25F_V3.json', 'r', encoding='utf-8'))\n",
    "\n",
    "#test = test[3154:3942]\n",
    "#test = test[9297:11620]\n",
    "labels_ = [row['label'] for row in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55c28735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load('D:\\\\predict_hfl_pretraineds_0511sentBase_document_article_epoch50_0519_BM25F_V3_9297_epoch__11\\\\pytorch_model.bin', map_location=torch.device('cuda'))\n",
    "model = BertForSequenceClassification.from_pretrained('D:\\\\hfl_pretraineds_0511sentBase_document_article_epoch50_0519', state_dict=model_state_dict, num_labels=3,output_attentions = False,output_hidden_states = False)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98365a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained('D:\\\\hfl')\n",
    "tokenizer = BertTokenizer.from_pretrained('D:\\\\hfl_pretraineds_0511sentBase_document_article_epoch50_0519')\n",
    "#tokenizer = BertTokenizer.from_pretrained(args.model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52ebd39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = json.load(open('D:\\\\download\\\\比賽\\\\CHEF-sbert\\\\Pipeline\\\\Data\\\\claim_cossim_hfl_pretraineds_0511sentBase_document_article_epoch50_0519_BM25F_V3.json', 'r', encoding='utf-8'))\n",
    "#sentence = sentence[3154:3942]\n",
    "#sentence = sentence[9297:11620]\n",
    "sentence = sentence[11620:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc870822",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "labels = []\n",
    "for i in range(len(sentence)):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        sentence[i],  # Sentence to encode.\n",
    "        add_special_tokens=False,  # Add '[CLS]' and '[SEP]'\n",
    "        max_length= 512,  # Pad & truncate all sentences.\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,  # Construct attn. masks.\n",
    "        return_tensors='pt',  # Return pytorch tensors.\n",
    "        truncation=True\n",
    "    )\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "    #labels.append(2)\n",
    "    labels.append(labels_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "234361be",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.cat(input_ids, dim=0).to(device)\n",
    "attention_masks = torch.cat(attention_masks, dim=0).to(device)\n",
    "labels = torch.tensor(labels, device='cuda')\n",
    "test_dataset = TensorDataset(input_ids, attention_masks,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18f9bd81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        sampler=SequentialSampler(test_dataset),   \n",
    "        batch_size=8 \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9357e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import datetime\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20770118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0096de2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Validation...\n",
      "Validation Elapsed: 0:09:26.\n",
      "Counter({0: 4512, 1: 2599, 2: 1927})\n",
      "       F1 (micro): 21.32%\n",
      "Precision (macro): 33.33%\n",
      "   Recall (macro): 7.11%\n",
      "       F1 (macro): 11.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NUI\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "best_microf1 = 0\n",
    "best_macrof1 = 0\n",
    "best_recall = 0\n",
    "best_precision = 0\n",
    "best_prediction = None\n",
    "best_ground_truth = None\n",
    "t0 = time.time()\n",
    "# Put the model in evaluation mode\n",
    "#model.forward()\n",
    "model.eval()\n",
    "print(\"Running Validation...\")\n",
    "# Tracking variables\n",
    "total_eval_accuracy = 0\n",
    "total_eval_loss = 0\n",
    "nb_eval_steps = 0\n",
    "all_prediction = np.array([])\n",
    "all_ground_truth = np.array([])\n",
    "all_logits = np.array([])\n",
    "#all_domains = np.array([])\n",
    "# Evaluate data for one epoch\n",
    "for batch in test_dataloader:\n",
    "    # Unpack this training batch from our dataloader.\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    #b_domains = batch[3].to('cpu').numpy()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            b_input_ids, \n",
    "            token_type_ids=None, \n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels\n",
    "        )\n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "    # Accumulate the validation loss.\n",
    "    total_eval_loss += loss.sum().item()\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "    labels_flat = label_ids.flatten()\n",
    "    #print('qqqq = ',all_prediction )\n",
    "    all_prediction = np.concatenate((all_prediction, pred_flat), axis=None)\n",
    "    #print('aaaa = ',all_prediction )\n",
    "    all_ground_truth = np.concatenate((all_ground_truth, labels_flat), axis=None)\n",
    "    #all_domains = np.concatenate((all_domains, b_domains), axis=None)\n",
    "    if len(all_logits) == 0:\n",
    "        all_logits = logits\n",
    "    else:\n",
    "        all_logits = np.concatenate((all_logits, logits), axis=0)\n",
    "\n",
    "# Calculate the average loss over all of the batches.\n",
    "avg_val_loss = total_eval_loss / len(test_dataloader)\n",
    "# Measure how long the validation run took.\n",
    "validation_time = format_time(time.time() - t0)\n",
    "print('Validation Elapsed: {:}.'.format(validation_time))\n",
    "# print(bert_type)\n",
    "c = Counter()\n",
    "for pred in all_prediction:\n",
    "    c[int(pred)] += 1\n",
    "print(c)\n",
    "pre, recall, f1, _ = precision_recall_fscore_support(all_ground_truth, all_prediction, average='micro')\n",
    "print(\"       F1 (micro): {:.2%}\".format(f1))\n",
    "microf1 = f1\n",
    "pre, recall, f1, _ = precision_recall_fscore_support(all_ground_truth, all_prediction, average='macro')\n",
    "print(\"Precision (macro): {:.2%}\".format(pre))\n",
    "print(\"   Recall (macro): {:.2%}\".format(recall))\n",
    "print(\"       F1 (macro): {:.2%}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b24c985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:\\\\download\\\\比賽\\\\all_prediction_predict_hfl_pretraineds_0511sentBase_document_article_epoch50_0519_BM25F_V3_9297.pickle', 'wb') as f:\n",
    "    pickle.dump(all_prediction, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eda99541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('D:\\\\download\\\\比賽\\\\CHEF-sbert\\\\Pipeline\\\\Data\\\\all_prediction_hfl_pretraineds_0511sentBase_document_article_epoch50_0519_BM25F_V3_9297_epoch_11.pickle', 'rb') as f:\n",
    "    label = (pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36b53862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 1070, 0: 729, 1: 524})\n"
     ]
    }
   ],
   "source": [
    "c_ = Counter()\n",
    "for pred in label:\n",
    "    c_[int(pred)] += 1\n",
    "print(c_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45911ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "701"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0\n",
    "for i in range(len(label)):\n",
    "    if label[i] == all_prediction[i]:\n",
    "        c+=1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59e5ac60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>from_py = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(labels)):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> label[i] == labels[i]:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 │   │   </span>from_py += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>from_py/<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(label)                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">IndexError: </span>index <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2323</span> is out of bounds for axis <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> with size <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2323</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0mfrom_py = \u001b[94m0\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m\u001b[94mfor\u001b[0m i \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(\u001b[96mlen\u001b[0m(labels)):                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 \u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m label[i] == labels[i]:                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m\u001b[2m│   │   \u001b[0mfrom_py += \u001b[94m1\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0mfrom_py/\u001b[96mlen\u001b[0m(label)                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mIndexError: \u001b[0mindex \u001b[1;36m2323\u001b[0m is out of bounds for axis \u001b[1;36m0\u001b[0m with size \u001b[1;36m2323\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from_py = 0\n",
    "for i in range(len(labels)):\n",
    "    if label[i] == labels[i]:\n",
    "        from_py += 1\n",
    "from_py/len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02bbc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_model = 0\n",
    "for i in range(len(labels)):\n",
    "    if all_prediction[i] == labels[i]:\n",
    "        from_model += 1\n",
    "from_model/len(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da65ce",
   "metadata": {},
   "source": [
    "epoch 1 : Counter({1: 663, 0: 124, 2: 1})\n",
    "epoch 4 : Counter({0: 409, 1: 305, 2: 74})\n",
    "        F1 (micro): 54.95%\n",
    "        Precision (macro): 54.01%\n",
    "        Recall (macro): 49.96%\n",
    "        F1 (macro): 49.79%\n",
    "        F1 (micro_read): 40.23%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2ae032",
   "metadata": {},
   "source": [
    "epoch 10 : Counter({0: 334, 1: 332, 2: 122})\n",
    "           F1 (micro): 62.18%\n",
    "           Precision (macro): 60.65%\n",
    "           Recall (macro): 58.80%\n",
    "           F1 (macro): 59.32%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08061c53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 1., 2., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 2., 0., 2., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 2., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 2., 0., 1., 1., 0.,\n",
       "       2., 2., 2., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 2., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 2., 1., 2., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 2., 0., 0., 0., 1., 2., 2., 0., 0., 1., 1., 0., 2., 0., 1.,\n",
       "       1., 1., 2., 1., 2., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 2., 1., 1., 0., 1., 1., 1., 0., 0., 2., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 2., 2., 2., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 2., 1., 2., 1., 0., 2., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 2., 1., 0., 0., 1., 0., 0., 0., 0., 0., 2.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 0., 0., 2., 1., 1., 0., 2., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 0., 1., 2., 2., 2., 0., 1., 2., 1., 0.,\n",
       "       0., 0., 2., 0., 1., 2., 2., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 2., 1., 1., 1., 1., 1., 1., 1., 2., 0., 1., 2., 1.,\n",
       "       0., 1., 0., 2., 0., 0., 0., 2., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 2., 0., 0., 2., 2., 1., 1., 0., 1., 1., 1., 2., 0., 1.,\n",
       "       2., 1., 0., 1., 1., 0., 1., 0., 0., 2., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 2.,\n",
       "       0., 0., 2., 2., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 2., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 2., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 2., 0., 1., 1., 2., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 2., 2., 2., 1., 2., 1., 1., 0., 1., 0., 1., 2., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       2., 2., 0., 1., 0., 1., 1., 2., 0., 1., 1., 1., 1., 1., 1., 2., 1.,\n",
       "       1., 2., 0., 0., 0., 1., 1., 0., 1., 1., 0., 2., 0., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 2., 1., 2., 2., 1., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
       "       1., 2., 2., 0., 1., 0., 0., 2., 2., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 0., 2., 1., 0., 1., 0., 1., 2., 1., 2., 0., 0., 1., 0., 2., 1.,\n",
       "       0., 0., 1., 2., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 2., 2.,\n",
       "       0., 1., 0., 1., 0., 1., 2., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 1., 0., 2., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 0., 2., 0., 1., 1., 1., 1., 1., 0.,\n",
       "       0., 2., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 2., 0.,\n",
       "       1., 0., 0., 1., 2., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 2., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 2., 0.,\n",
       "       2., 0., 1., 1., 0., 0., 1., 0., 1., 1., 2., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 0., 0., 2., 1., 1., 0., 0., 1., 2., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 1., 1., 2., 1., 1., 0., 1., 0., 1., 2.,\n",
       "       1., 1., 1., 1., 0., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db3abc3",
   "metadata": {},
   "source": [
    "epoch 0 : Counter({1: 705, 0: 82, 2: 1})\n",
    "          F1 (micro): 41.88%\n",
    "          Precision (macro): 63.98%\n",
    "          Recall (macro): 35.37%\n",
    "          F1 (macro): 26.34\n",
    "          F1 (micro_read): 40%\n",
    "epoch 1 : Counter({0: 425, 1: 339, 2: 24})\n",
    "          F1 (micro): 55.71%\n",
    "          Precision (macro): 59.14%\n",
    "          Recall (macro): 48.51%\n",
    "          F1 (macro): 46.18%\n",
    "          F1 (micro_read): 40.74%\n",
    "          \n",
    "epoch 2 : Counter({0: 366, 1: 317, 2: 105})\n",
    "          F1 (micro): 60.91%\n",
    "          Precision (macro): 59.61%\n",
    "          Recall (macro): 56.88%\n",
    "          F1 (macro): 57.35%\n",
    "          F1 (micro_read): %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d86bab72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2323"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f68b2e4",
   "metadata": {},
   "source": [
    "### Counter({1: 705, 0: 82, 2: 1})\n",
    "       F1 (micro): 41.88%\n",
    "Precision (macro): 63.98%\n",
    "   Recall (macro): 35.37%\n",
    "       F1 (macro): 26.34%\n",
    "            \n",
    "       \n",
    "Counter({0: 425, 1: 339, 2: 24})\n",
    "       F1 (micro): 55.71%\n",
    "Precision (macro): 59.14%\n",
    "   Recall (macro): 48.51%\n",
    "       F1 (macro): 46.18%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
